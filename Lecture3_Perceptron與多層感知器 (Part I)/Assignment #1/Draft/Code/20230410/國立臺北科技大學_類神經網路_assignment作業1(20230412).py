# -*- coding: utf-8 -*-
"""國立臺北科技大學_類神經網路_Assignment作業1(20230412).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10ec55fYau3lWtHP5frpkWJIf0rm9iEQE
"""

# 丟到模型前: pandas 
# 丟到模型時: numpy
import pandas as pd
import numpy as np
from copy import copy
iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')
iris_data = copy(iris)
iris

# 接下來要看模型Model，所以先將iris資料轉成array
iris_array = np.array(iris)
iris_array

"""第一題：要選擇怎樣的特徵"""

# 特徵選擇
# 1.) 具體、可觀察
# 2.) 可量化
# 3.) 具代表性，可區別

# 四個：無法視覺化，且沒有量化的指標代表混亂情況
# 選一個或兩個

sepal_length = iris_array[:, 0].astype(float) #'sepal length (cm)'
sepal_width = iris_array[:, 1].astype(float) #'sepal width (cm)'
petal_length = iris_array[:, 2].astype(float) #'petal length (cm)'
petal_width = iris_array[:, 3].astype(float) #'petal width (cm)'
target = iris_array[:, 4].astype(object)

import matplotlib.pyplot as plt
import seaborn as sns

# sepal length vs. sepal width
sns.scatterplot(x=sepal_length, y=sepal_width, hue=target)
plt.title('sepal length vs. sepal width')
plt.xlabel('sepal length')
plt.ylabel('sepal width')
plt.legend(['setosa', 'versicolor', 'virginica'], loc='upper right')

# sepal length vs. petal length
sns.scatterplot(x=sepal_length, y=petal_length, hue=target)
plt.title('sepal length vs. petal length')
plt.xlabel('sepal length')
plt.ylabel('petal length')
plt.legend(['setosa', 'versicolor', 'virginica'], loc='upper right')

sns.scatterplot(x=sepal_length, y=petal_width, hue=target)
plt.title('sepal length vs. petal width')
plt.xlabel('sepal length')
plt.ylabel('petal width')
plt.legend(['setosa', 'versicolor', 'virginica'], loc='upper right')

# sepal width vs. petal length
sns.scatterplot(x=sepal_width, y=petal_length, hue=target)
plt.title('sepal width vs. petal length')
plt.xlabel('sepal width')
plt.ylabel('petal length')
plt.legend(['setosa', 'versicolor', 'virginica'], loc='upper right')

# sepal width vs. petal width
sns.scatterplot(x=sepal_width, y=petal_width, hue=target)
plt.title('sepal width vs. petal width')
plt.xlabel('sepal width')
plt.ylabel('petal width')
plt.legend(['setosa', 'versicolor', 'virginica'], loc='upper right')

# petal length vs. petal width
sns.scatterplot(x=petal_length, y=petal_width, hue=target)
plt.title('petal length vs. petal width')
plt.xlabel('petal length')
plt.ylabel('petal width')
plt.legend(['setosa', 'versicolor', 'virginica'], loc='upper right')

iris['species'] = pd.factorize(iris['species'])[0]
iris

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

# 相關係數：兩個東西的相關性
# 完全正相關:1；完全負相關:-1
plt.figure(figsize=(14,10))
plt.title('Pearson Correlation', y=1.05, size=15)
sns.heatmap(iris.astype(float).corr(), linewidths=0.1, square=True, linecolor='white', annot=True, cmap="BrBG")

pd.DataFrame(iris.astype(float).corr())
# pd.DataFrame(iris.astype(float).corr()).to_excel("heatmap.xlsx")

# 選取特徵：petal length & petal width
iris_data = iris_data.drop(["sepal_length", "sepal_width"], axis=1)
iris_data

"""第二題：怎麼切分資料"""

# train_test_split
from sklearn.model_selection import train_test_split
train, test = train_test_split(iris_data, train_size=0.7, test_size = 0.2, shuffle=True, stratify=iris_data['species'])

# from sklearn.utils import resample
# train = resample(iris_data, n_samples=105, replace=False, stratify=iris_data['species'])

train

# train[train['species']=='setosa'].shape
# train[train['species']=='virginica'].shape
# train[train['species']=='versicolor'].shape

train_DataFrame = pd.DataFrame({'setosa資料數量：':[train[train['species']=='setosa'].shape[0]],
      'versicolor資料數量：':[train[train['species']=='versicolor'].shape[0]],
      'virginica資料數量：':[train[train['species']=='virginica'].shape[0]],
      }, index=['Count'])
train_DataFrame = train_DataFrame.T
train_DataFrame.columns
train_DataFrame

"""第三題：Perceptron Learning Algorithm"""

# 利用get_dummies
train = pd.get_dummies(train, columns=["species"])

# 利用轉換
# target_class = {
#     'setosa':1,
#     'virginica':-1,
#     'versicolor':-1
# }
# train['species'] = train['species'].map(target_class)
train

# 1.) 區分Setosa
train_petal_length = np.array(train)[:,0]
train_petal_width = np.array(train)[:,1]
species_setosa = np.array(train)[:,2]
# sns.scatterplot(x=train_petal_length, y=train_petal_width, hue=species_setosa)
sns.lmplot(x='petal_length', y='petal_width', data=train, fit_reg=False, hue ='species_setosa')

# Commented out IPython magic to ensure Python compatibility.
learning_rate = 0.001
Iters = 3000
no_of_inputs = 2
weights = np.array([0.,0.,0.]) 
data = train
hue='species_setosa'

def GetWeightandDrawPLA(learning_rate, Iters, weights, data, hue, no_of_inputs=2):
#   %pylab inline

  Err = []
    
  # 初始權重 (petal_length,petal_width,常數) → (W1,W2,W0) → (X1,X2,X0)
  # np.random.seed(10)
  # weights = np.random.randn(no_of_inputs + 1)
  print("initial: " + str(weights))

  inputs = np.array(data)[:,:2] #前兩欄為 'petal length'及'petal width'，轉成numpy array
  labels = np.array(data)[:,2] #第三欄為資料答案

  # 畫圖(PLA直線)
  # 定義X1和X2的範圍
  x_min, x_max = 0, 10
  y_min, y_max = 0, 10
  # 建立X1和X2的數組
  x1 = np.linspace(x_min, x_max, 10)
  x2 = np.linspace(y_min, y_max, 10)
  # 定義線性方程式
  def eq(x1, x2):
      return (weights[0]*x1 + weights[2])/(-weights[1])

  for iter_time in range(Iters): 
    err = 0
    for _input, label in zip(inputs, labels): 
      x,y = np.concatenate((_input, np.array([1.]))), label #將每一個_input都加上X0=1
      summation = np.dot(x, weights) # dot product
      if summation > 0: # the step activation function
        predicted = 1
      else: 
        predicted = 0
      weights += learning_rate * (label - predicted) * x

      if weights[2]!=0.0 and (weights[0])!=0.0:
        x_max = ((-weights[2])/(weights[0]))
        x1 = np.linspace(x_min, x_max, 10)
        
      # print("trained: " + str(weights))
      err += np.abs(label - predicted)
    Err.append(err)

    if sum(Err[-1:-5:-1]) == 0: break #假設後續測的5個err都是0

    print('第{}次執行'.format(iter_time))
    print("trained: " + str(weights))
    
    # 繪製線性方程式圖形
    # if iter_time % 5 == 0: # 每5次迭代畫一次分類線
    # sns.set(style="whitegrid")
    sns.lmplot(x='petal_length', y='petal_width', data=data, fit_reg=False, hue=hue)
    sns.lineplot(x=x1, y=eq(x1,x2), color='red')
    plt.xlabel('petal length (cm)')
    plt.ylabel('petal width (cm)')
    plt.title('Perceptron Learning Algorithm')
    plt.show()

  print("trained: " + str(weights))
  print(-weights[2]/weights[0])
  print(-weights[2]/weights[1])

  # 繪製線性方程式圖形
#   %pylab inline
  print('第{}次執行'.format(iter_time))
  # sns.set(style="whitegrid")
  sns.lmplot(x='petal_length', y='petal_width', data=data, fit_reg=False, hue=hue)
  sns.lineplot(x=x1, y=eq(x1,x2), color='red')
  plt.xlabel('petal length (cm)')
  plt.ylabel('petal width (cm)')
  plt.title('Perceptron Learning Algorithm')
  plt.show()

  plt.plot(range(0, len(Err)),Err)
  plt.xlabel('Iteration')
  plt.ylabel('loss/error')

  return weights

# weights = GetWeightandDrawPLA(learning_rate=0.95, Iters=5, weights=np.array([0.,0.,0.]), data=train, hue='species_setosa') # example

learning_rate = 0.95
Iters = 5

Err = []

no_of_inputs = 2

# 初始權重 (petal_length,petal_width,常數) → (W1,W2,W0) → (X1,X2,X0)
# np.random.seed(10)
# weights = np.random.randn(no_of_inputs + 1)
weights = np.array([0.,0.,0.]) 
print(weights)
print("initial: " + str(weights))

inputs = np.array(train)[:,:2]
labels = np.array(train)[:,2]

# 畫圖(PLA直線)
# 定義X1和X2的範圍
x_min, x_max = 0, 10
y_min, y_max = 0, 10
# 建立X1和X2的數組
x1 = np.linspace(x_min, x_max, 100)
x2 = np.linspace(y_min, y_max, 100)
# 定義線性方程式
def eq(x1, x2):
    return (weights[0]*x1 + weights[2])/(-weights[1])

for iter_time in range(Iters): 
  err = 0
  for _input, label in zip(inputs, labels): 
    x,y = np.concatenate((_input, np.array([1.]))), label #將每一個_input都加上X0=1
    summation = np.dot(x, weights) # dot product
    if summation > 0: # the step activation function
      predicted = 1
    else: 
      predicted = 0
    weights += learning_rate * (label - predicted) * x
    # print("trained: " + str(weights))
    err += np.abs(label - predicted)
  Err.append(err)
  print('第{}次執行'.format(iter_time))
  print("trained: " + str(weights))
  
  # 繪製線性方程式圖形
  # sns.set(style="whitegrid")
  sns.lmplot(x='petal_length', y='petal_width', data=train, fit_reg=False, hue ='species_setosa')
  sns.lineplot(x=x1, y=eq(x1,x2), color='red')
  plt.xlabel('petal length (cm)')
  plt.ylabel('petal width (cm)')
  plt.title('Perceptron Learning Algorithm')
  plt.show()

print("trained: " + str(weights))
print(-weights[2]/weights[0])
print(-weights[2]/weights[1])

# 繪製線性方程式圖形
# sns.set(style="whitegrid")
sns.lmplot(x='petal_length', y='petal_width', data=train, fit_reg=False, hue ='species_setosa')
sns.lineplot(x=x1, y=eq(x1,x2), color='red')
plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')
plt.title('Perceptron Learning Algorithm')
plt.show()

# 補畫圖

# weights= np.array([-2.47, -2.85,  5.7 ])

# x1 = np.linspace(x_min, (-weights[2])/(weights[0]), 100)

# # 繪製線性方程式圖形
# # sns.set(style="whitegrid")
# sns.lmplot(x='petal_length', y='petal_width', data=train, fit_reg=False, hue ='species_setosa')
# sns.lineplot(x=x1, y=eq(x1,x2), color='red')
# plt.xlabel('petal length (cm)')
# plt.ylabel('petal width (cm)')
# plt.title('Perceptron Learning Algorithm')
# plt.show()

# print("trained: " + str(weights))
# print(-weights[2]/weights[0])
# print(-weights[2]/weights[1])

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %pylab inline
plt.plot(range(0, len(Err)),Err)
plt.xlabel('Iteration')
plt.ylabel('loss/error')

# Filter Setosa 過濾Setosa資料
train[train['species_versicolor']==0][train['species_virginica']==0].index
for number in train[train['species_versicolor']==0][train['species_virginica']==0].index: 
  train = train.drop(index=number)
# train
train = train.drop(['species_setosa'], axis= 1)
print('資料比數:{}'.format(sum(train['species_versicolor'])+sum(train['species_virginica'])))
train

# 2.) 區分Versicolor
train_petal_length = np.array(train)[:,0]
train_petal_width = np.array(train)[:,1]
species_versicolor = np.array(train)[:,2]
sns.lmplot(x='petal_length', y='petal_width', data=train, fit_reg=False, hue ='species_versicolor')

# 第一階段
initial_weights = np.array([0.,0.,0.])
weights = GetWeightandDrawPLA(learning_rate=0.1, Iters=300, weights=initial_weights, data=train, hue='species_versicolor') # example

# 第二階段
print('initial_weights：{}'.format(weights)) 
weights = GetWeightandDrawPLA(learning_rate=0.01, Iters=300, weights=weights, data=train, hue='species_versicolor')

# 第三階段
print('initial_weights：{}'.format(weights)) 
weights = GetWeightandDrawPLA(learning_rate=0.001, Iters=300, weights=weights, data=train, hue='species_versicolor')

# 合併圖表
def eq(x1, x2):
    return (weights[0]*x1 + weights[2])/(-weights[1])

sns.lmplot(x='petal_length', y='petal_width', data=iris_data, fit_reg=False, hue ='species')

weights= np.array([-1.71,  -2.945,  7.6 ])
x1 = np.linspace(x_min, (-weights[2])/(weights[0]), 100)
sns.lineplot(x=x1, y=eq(x1,x2), color='red')

weights= np.array([-1.8486, -4.1222, 16.074 ])
x1 = np.linspace(x_min, (-weights[2])/(weights[0]), 100)
sns.lineplot(x=x1, y=eq(x1,x2), color='purple')

plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')
plt.title('Perceptron Learning Algorithm')
plt.show()

"""**第四題：量化Performance，評估**

"""

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

# test_3 = copy(test)

"""validation"""

# 取得Validation資料
validation=copy(iris_data)
for number in train.index: 
  validation = validation.drop(index=number, axis=1)
for number in test.index: 
  validation = validation.drop(index=number, axis=1)
print(validation.shape)
validation

validation = pd.get_dummies(validation, columns=["species"])
validation

def model_performance(data, weights, distinguish_flower):
  inputs = np.array(data)[:,:2] #前兩欄為 'petal length'及'petal width'，轉成numpy array
  labels = np.array(data)[:,2] #第三欄為資料答案
  ERR, predictions, answers = list(), list(), list()
  error = 0
  Error_to_DataFrame = pd.DataFrame()

  for _input, label in zip(inputs, labels): 
    x,y = np.concatenate((_input, np.array([1.]))), label #將每一個_input都加上X0=1
    summation = np.dot(x, weights) # dot product
    if summation > 0: # the step activation function
      predicted = 1
    else: 
      predicted = 0
    error = np.abs(label - predicted)
    predictions.append(predicted)
    answers.append(label)

    if error != 0.0: 
      ERR.append(error)
      Error_to_DataFrame = Error_to_DataFrame.append(pd.DataFrame(_input.tolist()+[label]+[predicted]).T)
    
  print('答對{}個'.format(accuracy_score(answers, predictions, normalize=False)))
  print('答錯{}個'.format(sum(ERR)))
  print(f'正確率：{accuracy_score(predictions, answers) *100}%')

  # 畫出Confusion Matrix
  mat = pd.DataFrame(confusion_matrix(answers, predictions), index=["不是"+distinguish_flower, distinguish_flower], columns=["不是"+distinguish_flower, distinguish_flower])

  # 告訴我哪幾個數值錯誤及答案、預測
  if sum(ERR) != 0:
    Error_to_DataFrame.columns=['petal length (cm)', 'petal width (cm)', 'label', 'predict']
    Error_to_DataFrame = Error_to_DataFrame.reset_index()
    Error_to_DataFrame = Error_to_DataFrame.drop('index', axis=1)
  
  return mat, Error_to_DataFrame

# 先驗證(Validation) Setosa資料集
weights = np.array([-1.71,  -2.945,  7.6 ])
mat, Error_to_DataFrame = model_performance(data=validation, weights=weights, distinguish_flower='Setosa')
mat

validation = validation[validation['species_setosa']!=1]
validation = validation.drop(['species_setosa'], axis=1)
validation

# 再驗證(Validation) Versicolor資料集
weights= np.array([-1.8486, -4.1222, 16.074 ])
mat, Error_to_DataFrame = model_performance(data=validation, weights=weights, distinguish_flower='Versicolor')
mat

Error_to_DataFrame

"""Test"""

test = pd.get_dummies(test, columns=["species"])
test

# 先測試(Test) Setosa資料集
weights = np.array([-1.71,  -2.945,  7.6 ])
mat, Error_to_DataFrame = model_performance(data=test, weights=weights, distinguish_flower='Setosa')
mat

test = test[test['species_setosa']!=1]
test = test.drop(['species_setosa'], axis=1)
test

# 再測試(Test) Versicolor資料集
weights= np.array([-1.8486, -4.1222, 16.074 ])
mat, Error_to_DataFrame = model_performance(data=test, weights=weights, distinguish_flower='Versicolor')
mat

Error_to_DataFrame

iris_data_versicolor = copy(iris_data)
iris_data_versicolor = pd.get_dummies(iris_data_versicolor, columns=["species"])
iris_data_versicolor = iris_data_versicolor[iris_data_versicolor['species_setosa']!=1]
iris_data_versicolor = iris_data_versicolor.drop('species_setosa', axis=1)

weights= np.array([-1.8486, -4.1222, 16.074 ])
mat, Error_to_DataFrame = model_performance(data=iris_data_versicolor, weights=weights, distinguish_flower='Versicolor')
mat

Error_to_DataFrame

"""計算 TP／TN／FP／FN

![.](https://miro.medium.com/v2/resize:fit:640/format:webp/1*BTB9weIUfSsSRy5kvh_-uA.png)
"""

# 正確率 Accuracy = (tp+tn)/(tp+fp+fn+tn)
# 精確率 Precision = tp/(tp+fp)
# 召回率 Recall = tp/(tp+fn)
tp = int(input('tp：'))
tn = int(input('tn：'))
fp = int(input('fp：'))
fn = int(input('fn：'))

print(f'正確率:{((tp+tn)/(tp+fp+fn+tn))*100}%')
print(f'Precision：{tp}/({tp}+{fp})={(tp/(tp+fp))*100}%')
print(f'Recall：{tp}/({tp}+{fn})={(tp/(tp+fn))*100}%')

'''
# 先測試Setosa資料集
inputs = np.array(validation)[:,:2] #前兩欄為 'petal length'及'petal width'，轉成numpy array
labels = np.array(validation)[:,2] #第三欄為資料答案
weights = np.array([-1.71,  -2.945,  7.6 ])
ERR, predictions, answers = list(), list(), list()
error = 0
Error_to_DataFrame = pd.DataFrame()

for _input, label in zip(inputs, labels): 
  x,y = np.concatenate((_input, np.array([1.]))), label #將每一個_input都加上X0=1
  summation = np.dot(x, weights) # dot product
  if summation > 0: # the step activation function
    predicted = 1
  else: 
    predicted = 0
  error = np.abs(label - predicted)
  predictions.append(predicted)
  answers.append(label)
  if error != 0.0: 
    ERR.append(error)
    Error_to_DataFrame.append(pd.DataFrame(_input.tolist()+[label]+[predicted]).T)
  
print('答對{}個'.format(accuracy_score(answers, predictions, normalize=False)))
print('答錯{}個'.format(sum(ERR)))
print(f'正確率：{accuracy_score(predictions, answers) *100}%')

# 畫出Confusion Matrix
mat = pd.DataFrame(confusion_matrix(answers, predictions), index=["Setosa", "不是Setosa"], columns=["Setosa", "不是Setosa"])

# 告訴我哪幾個數值錯誤及答案、預測
if sum(ERR) != 0:
  Error_to_DataFrame.columns=['petal length (cm)', 'petal width (cm)', 'label', 'predict']
  Error_to_DataFrame.reset_index()
'''

# pd.DataFrame(inputs)

# draft = pd.DataFrame()
# draft = draft.append(pd.DataFrame(_input.tolist()+[5]+[6]).T)
# draft = draft.append(pd.DataFrame(_input.tolist()+[5]+[6]).T)
# draft = draft.append(pd.DataFrame(_input.tolist()+[5]+[6]).T)
# draft.columns=['petal length (cm)', 'petal width (cm)', 'label', 'predict']
# draft.reset_index()

print(len(ERR))

(-1.85*1.4)+(-4.12*0.2)+16.07

print(_input)
print(label)
print(predicted)
Y = (-1.71*1.4)+(-2.945*0.2)+7.6
print(Y)

iris_data[iris_data['species_setosa']!=1]

'''
learning_rate = 0.001
Iters = 3000

Err = []

no_of_inputs = 2

# 初始權重 (petal_length,petal_width,常數) → (W1,W2,W0) → (X1,X2,X0)
# np.random.seed(10)
# weights = np.random.randn(no_of_inputs + 1)
weights = np.array([0.,0.,0.]) 
print(weights)
print("initial: " + str(weights))

inputs = np.array(train)[:,:2]
labels = np.array(train)[:,2]

# 畫圖(PLA直線)
# 定義X1和X2的範圍
x_min, x_max = 0, 10
y_min, y_max = 0, 10
# 建立X1和X2的數組
x1 = np.linspace(x_min, x_max, 10)
x2 = np.linspace(y_min, y_max, 10)
# 定義線性方程式
def eq(x1, x2):
    return (weights[0]*x1 + weights[2])/(-weights[1])

for iter_time in range(Iters): 
  err = 0
  for _input, label in zip(inputs, labels): 
    x,y = np.concatenate((_input, np.array([1.]))), label #將每一個_input都加上X0=1
    summation = np.dot(x, weights) # dot product
    if summation > 0: # the step activation function
      predicted = 1
    else: 
      predicted = 0
    weights += learning_rate * (label - predicted) * x

    if weights[2]!=0.0 and (weights[0])!=0.0:
      x_min, x_max = 0, ((-weights[2])/(weights[0]))
      x1 = np.linspace(x_min, x_max, 10)
      
    # print("trained: " + str(weights))
    err += np.abs(label - predicted)
  Err.append(err)

  if sum(Err[-1:-5:-1]) == 0: break #假設後續測的5個err都是0

  print('第{}次執行'.format(iter_time))
  print("trained: " + str(weights))
  
  # 繪製線性方程式圖形
  # if iter_time % 5 == 0: # 每5次迭代畫一次分類線
  # sns.set(style="whitegrid")
  sns.lmplot(x='petal_length', y='petal_width', data=train, fit_reg=False, hue ='species_versicolor')
  sns.lineplot(x=x1, y=eq(x1,x2), color='red')
  plt.xlabel('petal length (cm)')
  plt.ylabel('petal width (cm)')
  plt.title('Perceptron Learning Algorithm')
  plt.show()

print("trained: " + str(weights))
print(-weights[2]/weights[0])
print(-weights[2]/weights[1])

# 繪製線性方程式圖形
print('第{}次執行'.format(iter_time))
# sns.set(style="whitegrid")
sns.lmplot(x='petal_length', y='petal_width', data=train, fit_reg=False, hue ='species_versicolor')
sns.lineplot(x=x1, y=eq(x1,x2), color='red')
plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')
plt.title('Perceptron Learning Algorithm')
plt.show()
'''

# Commented out IPython magic to ensure Python compatibility.
'''
import matplotlib.pyplot as plt
# %pylab inline
plt.plot(range(0, len(Err)),Err)
plt.xlabel('Iteration')
plt.ylabel('loss/error')
'''

# print(-weights[2]/weights[0])
# print(-weights[2]/weights[1])
# print('第{}次執行'.format(iter_time))

# 補畫圖

# weights= np.array([-0.0016, -0.0247,  0.048])

# x1 = np.linspace(x_min, (-weights[2])/(weights[0]), 10)

# # 繪製線性方程式圖形
# # sns.set(style="whitegrid")
# sns.lmplot(x='petal_length', y='petal_width', data=train, fit_reg=False, )
# sns.lineplot(x=x1, y=eq(x1,x2), color='red')
# plt.xlabel('petal length (cm)')
# plt.ylabel('petal width (cm)')
# plt.title('Perceptron Learning Algorithm')
# plt.show()

# print("trained: " + str(weights))
# print(-weights[2]/weights[0])
# print(-weights[2]/weights[1])

"""[資料分析&機器學習] 第3.2講：線性分類-感知器(Perceptron) 介紹"""

# def sign(z):
#     if z > 0:
#         return 1
#     else:
#         return -1

# w = np.array([0.,0.,0.])
# error = 1 # error =1 主要是紀錄沒有錯誤分類的話就停止
# iterator = 0 # iterator主要是用來記錄更新了幾次

# # while error != 0:
# #     error = 0

# for i in range(len(train)):
#     x,y = np.concatenate((np.array([1.]), np.array(train.iloc[i])[:2])), np.array(train.iloc[i])[2]
#     print('y:{}'.format(y))
#     print('x:{}'.format(x))
#     # if sign(np.dot(w,x)) != y:
#     print("iterator: "+str(iterator))
#     iterator += 1
#     error += 1
#     sns.lmplot(x='petal_width', y='petal_length',data=train, fit_reg=False, hue ='species')
    
#     # 前一個Decision boundary 的法向量
#     if w[1] != 0:
#         x_last_decision_boundary = np.linspace(0,w[1])
#         y_last_decision_boundary = (w[2]/w[1])*x_last_decision_boundary
#         # plt.plot(x_last_decision_boundary, y_last_decision_boundary,'c--')
#     print('y:{}'.format(y))
#     print('x:{}'.format(x))
#     print('更新前的w:{}'.format(w))
#     w += y*x # 用來更新w     
#     print('更新後的w:{}'.format(w)) 
#     # print("x: " + str(x))            
#     # print("w: " + str(w))
#     # x向量 
#     x_vector = np.linspace(0,x[1])
#     y_vector = (x[2]/x[1])*x_vector
#     # plt.plot(x_vector, y_vector,'b')
#     # Decision boundary 的方向向量
#     x_decision_boundary = np.linspace(-0.5,7)
#     y_decision_boundary = (-w[1]/w[2])*x_decision_boundary - (w[0]/w[2])
#     plt.plot(x_decision_boundary, y_decision_boundary,'r')
#     # Decision boundary 的法向量
#     x_decision_boundary_normal_vector = np.linspace(0,w[1])
#     y_decision_boundary_normal_vector = (w[2]/w[1])*x_decision_boundary_normal_vector
#     plt.plot(x_decision_boundary_normal_vector, y_decision_boundary_normal_vector,'g')
#     plt.xlim(-0.5,7.5)
#     plt.ylim(5,-3)
#     plt.show()

# w = np.array([0.,0.,0.])
# error = 1 # error =1 主要是紀錄沒有錯誤分類的話就停止
# iterator = 0 # iterator主要是用來記錄更新了幾次
# while error != 0:
#     error = 0
#     for i in range(len(train)):
#         x,y = np.concatenate((np.array([1.]), np.array(train.iloc[i])[:2])), np.array(train.iloc[i])[2]

#         if sign(np.dot(w,x)) != y:
#             print("iterator: "+str(iterator))
#             iterator += 1
#             error += 1
#             sns.lmplot(x='petal_width', y='petal_length',data=train, fit_reg=False, hue ='species')
            
#             # 前一個Decision boundary 的法向量
#             if w[1] != 0:
#                 x_last_decision_boundary = np.linspace(0,w[1])
#                 y_last_decision_boundary = (w[2]/w[1])*x_last_decision_boundary
#                 # plt.plot(x_last_decision_boundary, y_last_decision_boundary,'c--')

#             print('y:{}'.format(y))
#             print('x:{}'.format(x))
#             print('更新前的w:{}'.format(w))
#             w += y*x # 用來更新w  
#             print('更新後')   
#             print("x: " + str(x))            
#             print("w: " + str(w))

#             # x向量 
#             x_vector = np.linspace(0,x[1])
#             y_vector = (x[2]/x[1])*x_vector
#             # plt.plot(x_vector, y_vector,'b')
#             # Decision boundary 的方向向量
#             x_decision_boundary = np.linspace(-0.5,7)
#             y_decision_boundary = (-w[1]/w[2])*x_decision_boundary - (w[0]/w[2])
#             plt.plot(x_decision_boundary, y_decision_boundary,'r')
#             # Decision boundary 的法向量
#             x_decision_boundary_normal_vector = np.linspace(0,w[1])
#             y_decision_boundary_normal_vector = (w[2]/w[1])*x_decision_boundary_normal_vector
#             plt.plot(x_decision_boundary_normal_vector, y_decision_boundary_normal_vector,'g')
#             plt.xlim(-0.5,7.5)
#             plt.ylim(-3,5)
#             plt.show()

