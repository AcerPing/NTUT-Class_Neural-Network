# -*- coding: utf-8 -*-
"""國立臺北科技大學_類神經網路_PLA(20230330).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_06-PuqSCIEOQgEAgdaucrSQQSj8KV02
"""

import numpy as np

inputs = list()
inputs.append(np.array([1, 1, 1]))
inputs.append(np.array([1, 0, 1]))
inputs.append(np.array([0, 1, 1]))
inputs.append(np.array([0, 0, 1]))

labels = np.array([1, 0, 0, 0]) # And Gate
# labels = np.array([1, 1, 1, 0]) # OR Gate

Iters = 10

no_of_inputs = 2
# np.random.seed(10)
weights = np.random.randn(no_of_inputs + 1)
print("initial: " + str(weights))

learning_rate = 0.15

for _ in range(Iters): 
  for _input, label in zip(inputs, labels): 
    summation = np.dot(_input, weights) # dot product
    if summation > 0: # the step activation function
      predicted = 1
    else: 
      predicted = 0
    weights += learning_rate * (label - predicted) * _input
print("trained: " + str(weights))

# 計算截距
x1 = 0.193/0.134
x1

# Commented out IPython magic to ensure Python compatibility.
Err = []
for _ in range(Iters): 
  err = 0
  for _input, label in zip(inputs, labels): 
    summation = np.dot(_input, weights) # dot product
    if summation > 0: # the step activation function
      predicted = 1
    else: 
      predicted = 0
    weights += learning_rate * (label - predicted) * _input
    err += np.abs(label - predicted)

  Err.append(err)

print("trained: " + str(weights))

import matplotlib.pyplot as plt
# %pylab inline
plt.plot(range(0, len(Err)),Err)
plt.xlabel('Iteration')
plt.ylabel('loss/error')

# 計算截距
# [ 0.15115068  0.1386053  -0.02563448]
print(0.02563448/0.1386053) # X2
print(0.02563448/0.15115068) # X1



